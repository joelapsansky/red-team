{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definte years\n",
    "string_2021 = \".y2021.html\"\n",
    "string_2020 = \".y2020.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = ['https://www.pgatour.com/content/pgatour/stats/stat.02567',\n",
    "'https://www.pgatour.com/content/pgatour/stats/stat.02674',\n",
    "'https://www.pgatour.com/content/pgatour/stats/stat.101',\n",
    "'https://www.pgatour.com/content/pgatour/stats/stat.02341',\n",
    "'https://www.pgatour.com/content/pgatour/stats/stat.496']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_2021 = [s + string_2021 for s in url_list]\n",
    "List_2020 = [s + string_2020 for s in url_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start out dataframes as empty lists (IDs listed in golfstats_FINAL_Excel file)\n",
    "# NOTE: This did not work when I made a list of lists using df = [[]] * 23 because you need to define\n",
    "## the lists in the list for the scrape function to work\n",
    "## just showing 2021 and 2020 in this notebook as an example\n",
    "\n",
    "df1 = []\n",
    "df2 = []\n",
    "df3 = []\n",
    "df4 = []\n",
    "df5 = []\n",
    "df6 = []\n",
    "df7 = []\n",
    "df8 = []\n",
    "df9 = []\n",
    "df10 = []\n",
    "\n",
    "dataframe_2021 = [df1,df2,df3,df4,df5]\n",
    "dataframe_2020 = [df6,df7,df8,df9,df10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scrape function using dynamic dataframe variable names\n",
    "## This method makes the above step necessary\n",
    "\n",
    "def scrape(List_year, df):\n",
    "    \n",
    "    # Enumerate url list and loop through it\n",
    "    for index, url in enumerate(List_year):\n",
    "        \n",
    "        # Print start\n",
    "        start = time.time()\n",
    "\n",
    "        print(f\"Start loop {index+1}\")\n",
    "\n",
    "         # Set the executable path and initialize the chrome browser in splinter\n",
    "        executable_path = {'executable_path': 'chromedriver'}\n",
    "        browser = Browser('chrome', **executable_path)\n",
    "    \n",
    "        # Pause 3 seconds so as not to overwhelm server\n",
    "        time.sleep(3)\n",
    "    \n",
    "        # Visit URL, parse, find table\n",
    "        browser.visit(url)\n",
    "        browser.is_element_present_by_css(\"ul.item_list li.slide\", wait_time=1)\n",
    "        html = browser.html\n",
    "        golf_soup = soup(html, 'html.parser')\n",
    "        table = golf_soup.find('table', class_='table-styled')\n",
    "    \n",
    "        # Find rows and headings\n",
    "        table_rows = table.find('tbody').find_all('tr')\n",
    "        table_headings = table.find('thead').find_all('th')\n",
    "    \n",
    "        # Strip column name text and append to dfs\n",
    "        column_names = [cm.text.strip() for cm in table_headings]\n",
    "        df[index].append(column_names)\n",
    "    \n",
    "        # Strip row text and append to dfs\n",
    "        for tr in table_rows:\n",
    "            rows = [tr.text.strip() for tr in tr.find_all('td')]\n",
    "            df[index].append(rows)\n",
    "    \n",
    "        # Convert list to pandas dataframe\n",
    "        df[index]= pd.DataFrame(df[index])\n",
    "    \n",
    "        # Promote headers\n",
    "        header = df[index].iloc[0]\n",
    "        df[index] = df[index][1:]\n",
    "        df[index].columns = header\n",
    "    \n",
    "        # Set Index equal to PLAYER NAME\n",
    "        df[index] = df[index].set_index('PLAYER NAME')\n",
    "    \n",
    "        # Quit browser\n",
    "        browser.quit()\n",
    "    \n",
    "        # Print progress\n",
    "        print(f\"End loop {index+1} | Elapsed loop time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loop 1\n",
      "End loop 1 | Elapsed loop time: 14.76287579536438\n",
      "Start loop 2\n",
      "End loop 2 | Elapsed loop time: 16.69131374359131\n",
      "Start loop 3\n",
      "End loop 3 | Elapsed loop time: 13.922194004058838\n",
      "Start loop 4\n",
      "End loop 4 | Elapsed loop time: 16.66594433784485\n",
      "Start loop 5\n",
      "End loop 5 | Elapsed loop time: 15.548963069915771\n"
     ]
    }
   ],
   "source": [
    "# Run scrape 2021\n",
    "scrape(List_2021, dataframe_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loop 1\n",
      "End loop 1 | Elapsed loop time: 15.853954553604126\n",
      "Start loop 2\n",
      "End loop 2 | Elapsed loop time: 20.165733814239502\n",
      "Start loop 3\n",
      "End loop 3 | Elapsed loop time: 17.83914566040039\n",
      "Start loop 4\n",
      "End loop 4 | Elapsed loop time: 15.73022985458374\n",
      "Start loop 5\n",
      "End loop 5 | Elapsed loop time: 20.11806583404541\n"
     ]
    }
   ],
   "source": [
    "# Run scrape 2020\n",
    "scrape(List_2020, dataframe_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all columns to make them unique (took this code from our Excel formulas)\n",
    "# Renaming each dataframe using this method is necessary because of how I needed\n",
    "## to do it above to make the scrape function work the way I wanted\n",
    "df1=dataframe_2021[0][['AVERAGE']].rename(columns={'AVERAGE': 'SG_off_tee_2021_AVERAGE'})\n",
    "df2=dataframe_2021[1][['AVERAGE']].rename(columns={'AVERAGE': 'SG_tee_green_2021_AVERAGE'})\n",
    "df3=dataframe_2021[2][['AVG.']].rename(columns={'AVG.': 'driving_dist_2021_AVG.'})\n",
    "df4=dataframe_2021[3][['AVG (%)']].rename(columns={'AVG (%)': 'pct_ydg_tee_2021_AVG (%)'})\n",
    "df5=dataframe_2021[4][['%']].rename(columns={'%': 'driving_320+_2021_%'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 2020\n",
    "df6=dataframe_2020[0][['AVERAGE']].rename(columns={'AVERAGE': 'SG_off_tee_2020_AVERAGE'})\n",
    "df7=dataframe_2020[1][['AVERAGE']].rename(columns={'AVERAGE': 'SG_tee_green_2020_AVERAGE'})\n",
    "df8=dataframe_2020[2][['AVG.']].rename(columns={'AVG.': 'driving_dist_2020_AVG.'})\n",
    "df9=dataframe_2020[3][['AVG (%)']].rename(columns={'AVG (%)': 'pct_ydg_tee_2020_AVG (%)'})\n",
    "df10=dataframe_2020[4][['%']].rename(columns={'%': 'driving_320+_2020_%'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all on index already set to create final dataset\n",
    "final_df = df1.join(df2).join(df3).join(df4).join(df5).join(df6).join(df7).join(df8).join(df9).join(df10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat names with symbols\n",
    "new_name_format = {'Sebasti치n Mu침oz':'Sebastian Munoz',\\\n",
    "             'Fabi치n G칩mez':'Fabian Gomez'}\n",
    "           \n",
    "final_df = final_df.rename(index=new_name_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all blank rows (some players have only played one year and we're choosing to exclude them)\n",
    "full_final_df = final_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found code on Stack Overflow and ammended it to convert measurement columns to numbers without symbols\n",
    "# Didn't include these columns in the rewrite, but if you had the columns, this is how you'd do it\n",
    "def parse_measurements(i):\n",
    "    measurement_ = i.split(\"' \")\n",
    "    ft_ = float(measurement_[0])\n",
    "    in_ = float(measurement_[1].replace(\"\\\"\",\"\"))\n",
    "    return (12*ft_) + in_\n",
    "\n",
    "# # Comment out because I didn't include these columns in the rewrite\n",
    "# full_final_df['fwy_prox_2021_AVG'] = full_final_df['fwy_prox_2021_AVG'].apply(lambda x:parse_measurements(x))\n",
    "# full_final_df['rough_prox_2021_AVG'] = full_final_df['rough_prox_2021_AVG'].apply(lambda x:parse_measurements(x))\n",
    "# full_final_df['fwy_prox_2020_AVG'] = full_final_df['fwy_prox_2020_AVG'].apply(lambda x:parse_measurements(x))\n",
    "# full_final_df['rough_prox_2020_AVG'] = full_final_df['rough_prox_2020_AVG'].apply(lambda x:parse_measurements(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do same thing with $ column\n",
    "# Didn't include these columns in the rewrite, but if you had the columns, this is how you'd do it\n",
    "def parse_money_symbol(i):\n",
    "    symbol_ = i.split(\"$\")\n",
    "    number = float(symbol_[1].replace(\",\",\"\"))\n",
    "    return number\n",
    "\n",
    "# # Comment out because I didn't include these columns in the rewrite\n",
    "# full_final_df['money_2021_MONEY'] = full_final_df['money_2021_MONEY'].apply(lambda x: parse_money_symbol(x))\n",
    "# full_final_df['money_2020_MONEY'] = full_final_df['money_2020_MONEY'].apply(lambda x: parse_money_symbol(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to numberic and send to csv\n",
    "cleaned_final_df = full_final_df.apply(pd.to_numeric)\n",
    "\n",
    "# cleaned_final_df.to_csv('cleaned_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
